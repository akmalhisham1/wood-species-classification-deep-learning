{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uWbgefm8f6wS"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation,Dense,Flatten,BatchNormalization,Conv2D,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import skimage\n",
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "from tensorflow.keras.applications.resnet50  import ResNet50  \n",
    "from tensorflow.keras.applications.resnet50  import preprocess_input\n",
    "#SET SIZE GAMBAR, KENAPA 71? SEBAB 200 BERAT SGT FOR CPU SLOW, AND MIN INPUT IS 71 FOR XCEPTION\n",
    "IMAGE_WIDTH = 71\n",
    "IMAGE_HEIGHT = 71\n",
    "IMAGE_SIZE = [71, 71]\n",
    "\n",
    "#BATCH SIZE SET 1 KALO XDE GPU SO CPU MMG SLOW XLEH BESAR2\n",
    "BATCH_SIZE_HERE = 1\n",
    "conv_base = ResNet50 (input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "#SET UNTUK TRANSFER LEARNING (TAK NAK UPDATE WEIGHTS ON PRE-TRAINED LAYERS)\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#UPDATE OPTIONS HERE\n",
    "namaModel = 'RESNET50-71'\n",
    "experimentFolder = 'EXPERIMENT-RESNET50-71'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv4nC-Gof9HY",
    "outputId": "1150419f-5581-4d63-9928-1944c3bcdd84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1919 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "tambah_augmentation = True\n",
    "if(tambah_augmentation):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "           rescale=1./IMAGE_WIDTH, # resize kepada 71x71\n",
    "                 rotation_range=0,\n",
    "                 width_shift_range=0.05, # ubah gamabr kiri kanan 5%\n",
    "                 height_shift_range=0.05,# ubah gamabr atas bawah 5%\n",
    "                 zoom_range=0.05, # ubah zoom in/out 5% \n",
    "                 horizontal_flip=True, # boleh flip 180 degeree atas ke bawah\n",
    "                 vertical_flip= True,# boleh flip 180 degeree kanan ke kiri\n",
    "                 fill_mode='nearest', # isis ruang kosong  style nearest standard\n",
    "              \n",
    "        )\n",
    "else:\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./IMAGE_WIDTH) # xde augmentation just resize image 71x71\n",
    "#set input data folder kat mana untuk training\n",
    "train_dir = 'CUSTOM_SAMPLE/train' \n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(IMAGE_WIDTH,IMAGE_HEIGHT),# 71x71\n",
    "                                                    batch_size= BATCH_SIZE_HERE,\n",
    "                                                    class_mode='categorical', # lebih dari 2 classs so categorical not binary\n",
    "                                                    classes=[\"1\", \"10\",\"11\",\"12\"],# nama class yg nak masuk training\n",
    "                                                    follow_links=True, # default\n",
    "                                                    shuffle=False)# default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouN7ui-3gpft",
    "outputId": "b7484f35-5049-4999-aa93-bf48884cf423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 271 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation set xleh augment nnti salah \n",
    "val_dir = 'CUSTOM_SAMPLE/test'\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./IMAGE_WIDTH)\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                         target_size=(IMAGE_WIDTH,IMAGE_HEIGHT),# 71x71\n",
    "                                                        batch_size= BATCH_SIZE_HERE,\n",
    "                                                        class_mode='categorical',# lebih dari 2 classs so categorical not binary\n",
    "                                                        classes=[\"1\",\"10\",\"11\",\"12\"],# nama class yg nak masuk training\n",
    "                                                        follow_links=True,# default\n",
    "                                                        shuffle=False)# default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s2UWv_hbizhR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Steps Per Epcoh:  1919\n",
      "Validation Steps Per Epcoh:  271\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "currentTimeUnix = str(int(time.time())) \n",
    "ExperimentPath = experimentFolder+'-'+currentTimeUnix\n",
    "os.mkdir(ExperimentPath)\n",
    "\n",
    "\n",
    "train_steps = int(np.ceil(1919/BATCH_SIZE_HERE)) \n",
    "val_steps = int(np.ceil(271  /BATCH_SIZE_HERE)) \n",
    "print(\"Training Steps Per Epcoh: \",train_steps)\n",
    "print(\"Validation Steps Per Epcoh: \",val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_prB5d1i2Ch",
    "outputId": "2a7910dc-953a-4735-e260-c1c33a972ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 3, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 73732     \n",
      "=================================================================\n",
      "Total params: 23,661,444\n",
      "Trainable params: 73,732\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "    \n",
    "model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e-lSYvUi3Ia",
    "outputId": "4ffb2d50-6bd9-4c0f-e671-816e737dee7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1919/1919 [==============================] - 28s 11ms/step - loss: 1.1648 - accuracy: 0.5873 - val_loss: 0.7999 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79991, saving model to EXPERIMENT-RESNET50-71-1656602708\\BestLossModel.h5\n",
      "Epoch 2/25\n",
      "1919/1919 [==============================] - 29s 15ms/step - loss: 0.9258 - accuracy: 0.6696 - val_loss: 0.8178 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.79991\n",
      "Epoch 3/25\n",
      "1919/1919 [==============================] - ETA: 0s - loss: 0.9363 - accuracy: 0.6936"
     ]
    }
   ],
   "source": [
    "filepath = ExperimentPath+'/BestLossModel.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, patience=2,\n",
    "                             save_best_only=True, mode='min')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='min', min_lr=0.0001)\n",
    "\n",
    "#Save log untuk tensorflow tensorboard files untuk plot graph                                \n",
    "log_dir = ExperimentPath+\"/logs/\" +namaModel+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)                             \n",
    "callbacks_list = [checkpoint, reduce_lr,tensorboard_callback]\n",
    "\n",
    "#Start Training and save history\n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=train_steps, \n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=25, \n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                    #class_weight=class_weight\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "ikRJh_EZi5mt",
    "outputId": "96e01ec1-d36b-433f-cd78-ac36df8eb199"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "FinalEpochModel = ExperimentPath+'/FINAL_EPOCH_MODEL.h5'\n",
    "model.save(FinalEpochModel)\n",
    "val_set = validation_generator\n",
    "# plot the loss\n",
    "fig=plt.figure()\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history[\n",
    "    'val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig(ExperimentPath+'/Loss.png',dpi=200)\n",
    "\n",
    "# PLOT ACCURACY FOR ALL REPOCH\n",
    "fig=plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig(ExperimentPath+'/Accuracy.png',dpi=200)\n",
    "\n",
    "with open(ExperimentPath+'/modelsummary.txt', 'w') as f:\n",
    "\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#RELOAD BEST LOSS MODEL AND RUN TEST\n",
    "model.load_weights(filepath)\n",
    "val_loss, val_acc = model.evaluate(val_set)\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)\n",
    "\n",
    "predictions_proba = model.predict(val_set, verbose=1)\n",
    "test_labels = val_set.classes\n",
    "\n",
    "file1 = open(ExperimentPath+\"/report.csv\",\"w\")\n",
    "file2 = open(ExperimentPath+\"/report_summary.txt\",\"w\")\n",
    "\n",
    "print(\"Total Testing Data \",len(val_set.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tFSZ6whi8KP",
    "outputId": "314d35fd-6ac1-4124-fedb-1fdb237d4459"
   },
   "outputs": [],
   "source": [
    "VAL_SET_INPUT =\"test\"\n",
    "\n",
    "file2.write(\"Val Data Source: \"+VAL_SET_INPUT)\n",
    "TotalAll = len(val_set.filenames)\n",
    "file2.write(\"\\nTotal Testing Data \"+str(TotalAll))\n",
    "file2.write(str(val_set.class_indices))\n",
    "\n",
    "file2.write(\"\\nPrediction on Validation: \"+str(TotalABN))\n",
    "file2.write('\\nval_loss: '+ str(round(val_loss,5)))\n",
    "file2.write('\\nval_acc: '+ str(round(val_acc,5)))\n",
    "\n",
    "file1.write('No.,Filename,Label,Prediction,Keputusan,\\n')\n",
    "\n",
    "for i in range(len(val_set.filenames)):    \n",
    "    print(i,\",\",val_set.filenames[i],\",\", val_set.classes[i], \",\",predictions_proba[i],',',predictions_proba[i].argmax(axis=0) ==  val_set.classes[i])\n",
    "    # \\n is placed to indicate EOL (End of Line)\n",
    "    file1.write(str(i)+\",\"+val_set.filenames[i]+\",\"+ str(val_set.classes[i])+\",\"+str(predictions_proba[i][0])+\",\"+str(predictions_proba[i][1])+','+str(predictions_proba[i].argmax(axis=0) ==  val_set.classes[i])+'\\n')\n",
    "file1.close() #to change file access modes\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOduzlCw9dx0"
   },
   "outputs": [],
   "source": [
    "CF_NAME ='';\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[1]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ExperimentPath+'/Confusion_Matrix_'+CF_NAME+'.png',dpi=200)\n",
    "    plt.clf\n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix_Normalized(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[1]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ExperimentPath+'/Confusion_Matrix_Normalized_'+CF_NAME+'.png',dpi=200)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "LNzg56xy9hrK",
    "outputId": "aea6f64d-ae6d-4803-c1f8-faa573555b2c"
   },
   "outputs": [],
   "source": [
    "# Define the labels of the class indices. These need to match the \n",
    "# order shown above.\n",
    "CF_NAME = 'VAL_BESTLOSSMODEL'\n",
    "\n",
    "cm = confusion_matrix(val_set.classes,predictions_proba.argmax(axis=1))\n",
    "cm_plot_labels = [ '1','10','11','12']\n",
    "plt.clf\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "1uqobl7x9jTz",
    "outputId": "8d59d5b4-d823-4fc0-d0ff-f145e7210538"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix_Normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Downloads\\.ipynb_checkpoints\\TrainNowRESNET50-GPU-checkpoint.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Downloads/.ipynb_checkpoints/TrainNowRESNET50-GPU-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# argmax returns the index of the max value in a row\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Downloads/.ipynb_checkpoints/TrainNowRESNET50-GPU-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plot_confusion_matrix_Normalized(cm, cm_plot_labels, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mConfusion Matrix-\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_confusion_matrix_Normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# argmax returns the index of the max value in a row\n",
    "\n",
    "plot_confusion_matrix_Normalized(cm, cm_plot_labels, title='Confusion Matrix-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5rJktEt9lDs",
    "outputId": "4ef6c46e-b46f-46aa-eff2-04be52fe7b82"
   },
   "outputs": [],
   "source": [
    "test_filenames = val_set.filenames\n",
    "# Get the true labels\n",
    "y_true = val_set.classes\n",
    "# Get the predicted labels\n",
    "y_pred = predictions_proba.argmax(axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n",
    "print(report)\n",
    "file3 = open(ExperimentPath+\"/CF_SUMMARY.txt\",\"w\")\n",
    "file3.write(report)\n",
    "file3.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TrainNow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
